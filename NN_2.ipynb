{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "zHSWCXF_6TqZ",
    "outputId": "24d41c9b-bc5c-4685-a1a1-4d123ad4f977"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as  plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import OrderedDict\n",
    "import torchvision.models as  models\n",
    "import itertools\n",
    "import math\n",
    "from torch.optim import lr_scheduler\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from PIL import Image\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8YbKw01g6Tqj"
   },
   "outputs": [],
   "source": [
    "# #Building a MTCNN object \n",
    "# detector = MTCNN()\n",
    "# #Funtion that takes an image and crops the facial part of the image using MTCNN\n",
    "# def crop_face(x):\n",
    "#     x = np.array(x)\n",
    "#     faces = detector.detect_faces(x)\n",
    "#     if len(faces)==0:\n",
    "#         return Image.fromarray(x)\n",
    "#     for face in faces:\n",
    "#         x1, y1, width, height = face['box']\n",
    "#         x2, y2 = x1 + width, y1 + height\n",
    "#         if x1<0:\n",
    "#             x1=0\n",
    "#         if y1 < 0:\n",
    "#             y1=0\n",
    "#         cropped_face = x[y1:y2,x1:x2]\n",
    "#         cropped_face = Image.fromarray(cropped_face.astype('uint8'))\n",
    "#         return cropped_face\n",
    "# #Directory where we have the original images\n",
    "# data_dir = 'Subset For Assignment SFEW'\n",
    "# for i in os.listdir(data_dir):\n",
    "#     for j in os.listdir(data_dir+'/'+i):\n",
    "#         img = Image.open(data_dir+'/'+i+'/'+j)\n",
    "#         #cropping faces of all the images in the directory\n",
    "#         crop_faces = crop_face(img)\n",
    "#         if not os.path.exists('new_data'+'/'+i):\n",
    "#             #making new directory to keep cropped images \n",
    "#             os.makedirs('new_data'+'/'+i)\n",
    "#         crop_faces.save('new_data'+'/'+i+'/'+j)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "2FJymEoS6Tqp",
    "outputId": "0449c2fa-ef5e-4a63-8dcc-8ee344655096"
   },
   "outputs": [],
   "source": [
    "path = ('cropped_SFEW')\n",
    "# Performing data augmentation before sending it to the Network\n",
    "TRANSFORM_IMG = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.Resize((224,224)),#Standard ImageNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))#standard ImageNet\n",
    "    ])\n",
    "#Transforming all the images using ImageFolder\n",
    "full_dataset = torchvision.datasets.ImageFolder(root=path,transform=TRANSFORM_IMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a14mBvey6Tqw"
   },
   "outputs": [],
   "source": [
    "train_size = int(0.80* len(full_dataset)) # 80% for training\n",
    "valid_size =  int(0.10* len(full_dataset))# 10% for validation\n",
    "test_size = int(0.101* len(full_dataset)) # 10% for testing\n",
    "train_dataset,valid_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size,valid_size, test_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oq0W0Rnu6Tq3"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True,num_workers = 0)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=32, shuffle=False,num_workers = 0)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False,num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "colab_type": "code",
    "id": "5fEEIrRq6Tq9",
    "outputId": "0f8f722f-de97-4dc3-cc95-876b8ef211b4"
   },
   "outputs": [],
   "source": [
    "#Plotting sample images that are fed to the network\n",
    "samples, labels = iter(train_loader).next()\n",
    "plt.figure(figsize=(16,24))\n",
    "grid_imgs = torchvision.utils.make_grid(samples[:24])\n",
    "np_grid_imgs = grid_imgs.numpy()\n",
    "plt.imshow(np.transpose(np_grid_imgs, (1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TCJV47cG6TrH"
   },
   "outputs": [],
   "source": [
    "#5 pretrained models were used .For chosing any other model the final pooled neurons number should \n",
    "#be changed according to the mdoel used. \n",
    "\n",
    "\n",
    "#base_model = models.resnet152(pretrained = True)\n",
    "base_model = models.alexnet(pretrained = True)\n",
    "#base_model = models.vgg13(pretrained = True)\n",
    "#base_model = models.resnet50(pretrained = True)\n",
    "#base_model = models.resnet18(pretrained = True)\n",
    "\n",
    "#Net that uses all the layers except the final layer of the pretrained models and fine tunes the fully connected layers.\n",
    "class FineTuneModel(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(FineTuneModel, self).__init__()\n",
    "        # Everything except the last linear layer\n",
    "        self.features = nn.Sequential(*list(base_model.children())[:-1])\n",
    "        self.classifier = nn.Linear(9216,200)\n",
    "        self.fc = nn.Linear(200,7)\n",
    "        self.drop_out = nn.Dropout(0.5)\n",
    "        # Freeze those weights\n",
    "        for p in self.features.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.features(x)        \n",
    "        f = f.view(f.size(0), -1)\n",
    "        y = self.classifier(f)\n",
    "        cl_out = torch.sigmoid(y)\n",
    "        drop = self.drop_out(cl_out)\n",
    "        f = self.fc(drop)\n",
    "        return f,cl_out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "fEXyRK466TrO",
    "outputId": "052f9ec8-06a3-4490-d95d-d8c4e2e0b9f1"
   },
   "outputs": [],
   "source": [
    "model= FineTuneModel(base_model)\n",
    "\n",
    "# Own implementation of CNN \n",
    "# for 1 convoutional layer self.layer2 has to be removed  \n",
    "\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.layer1 = nn.Sequential(\n",
    "#             nn.Conv2d(3,16, kernel_size=5, stride=1, padding=2),\n",
    "#             nn.BatchNorm2d(16),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#             nn.Dropout2d(0.5))\n",
    "#         self.layer2 = nn.Sequential(\n",
    "#             nn.Conv2d(16, 32, kernel_size=7, stride=1, padding=3),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#             nn.Dropout2d(0.5))\n",
    "#         self.fc = nn.Linear(74*74*32,100)\n",
    "#         self.drop = nn.Dropout(0.4)\n",
    "#         self.fc1=nn.Linear(100,7)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = self.layer1(x)\n",
    "#         out = self.layer2(out)\n",
    "#         out = out.reshape(out.size(0), -1)\n",
    "#         out = self.fc(out)\n",
    "#         out = torch.tanh(out)\n",
    "#         out = self.drop(out)\n",
    "#         out = self.fc1(out)\n",
    "#         return out\n",
    "\n",
    "#  Create an instance of the model class \n",
    "#model = Net()\n",
    "#Find total parameters and trainable parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} training parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oBRH754v6TrX"
   },
   "outputs": [],
   "source": [
    "#Different learning rate and scheduler and optimizers were tried.\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# plist = [\n",
    "#         {'params': model.classifier.parameters(), 'lr': 5e-3,\n",
    "#          'params1' : model.fc.parameters(),'lr':5e-3}\n",
    "#         ]\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#lr_sch = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay = 1e-5)\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "aT9wURM-6Trd",
    "outputId": "af05d5c7-cf0f-4615-ddb6-395082211afc"
   },
   "outputs": [],
   "source": [
    "# Set the model to training mode\n",
    "if (torch.cuda.is_available()):\n",
    "  model=model.cuda()\n",
    "num_epochs = 50\n",
    "all_train_losses=[]\n",
    "all_val_loss = []\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    hidden = []\n",
    "    # Process the images in batches\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Use the CPU or GPU as appropriate\n",
    "        if (torch.cuda.is_available()):\n",
    "\n",
    "          data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        # Reset the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Push the data forward through the model layers\n",
    "        output,h1= model(data)\n",
    "        hidden.append(h1)\n",
    "        # Get the loss\n",
    "        loss = criterion(output,target)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #lr_sch.step()\n",
    "    # return average loss for the epoch\n",
    "    res = torch.cat(hidden,dim=0)\n",
    "    avg_loss = train_loss / (batch_idx+1)\n",
    "    all_train_losses.append(avg_loss)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        val_loss = 0\n",
    "        #all_val_loss = []\n",
    "        for batch,(images, labels) in enumerate(valid_loader):\n",
    "\n",
    "\n",
    "            if (torch.cuda.is_available()):\n",
    "              images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "\n",
    "            outputs,h_test= model(images)\n",
    "            v_loss = criterion(outputs,labels)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            val_loss+=v_loss.item()\n",
    "    avg_val_loss = val_loss/(batch+1)\n",
    "    all_val_loss.append(avg_val_loss)\n",
    "    print('Epoch : {}/{} Training set: Average loss: {:.2f} val_loss : {:.2f} val_accuracy : {:.2f}'.format(epoch+1 , num_epochs,avg_loss,avg_val_loss,100*correct/total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "y3PK2YXU6Trk",
    "outputId": "800dc65f-386a-42d5-8395-88712ec11acd"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "# Model allocated to evaluation mode . No gradient update from here. \n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pred = []\n",
    "    label= []\n",
    "    #Setting seed to 0 as dataloader allocates random sequences of input.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    random.seed(0)\n",
    "    for images, labels in test_loader:\n",
    "        if (torch.cuda.is_available()):\n",
    "\n",
    "          images, labels = images.cuda(), labels.cuda()\n",
    "        outputs,h= model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        pred.append(predicted)\n",
    "        label.append(labels)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    l_ = torch.cat(label)\n",
    "    pred_ = torch.cat(pred)\n",
    "    print('Test Accuracy of the model on the  test images: {:.2f} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "rLKfozW4Ry6-",
    "outputId": "268f70c2-8777-4026-c4a3-302ce6bb71f6"
   },
   "outputs": [],
   "source": [
    "#class wise precision recall and f1-score\n",
    "print(\"Evaluation of our model on test set\")\n",
    "testing_pred = pred_.cpu()\n",
    "actual = l_.cpu()\n",
    "target_names = ['Angry','Disgust','Fear','Happy','Neutral','Sad','Surprise']\n",
    "print(classification_report(testing_pred,actual,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "zvVl3XqB6Trr",
    "outputId": "a11c44e3-9b6f-4c29-b80d-306e7d7d6fd4"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Extracting the hidden layer output to perform pruning\n",
    "k_array=np.array(res.cpu().detach())\n",
    "scaler = MinMaxScaler()\n",
    "pattern_vector=k_array.T\n",
    "pattern_vector=scaler.fit_transform(pattern_vector)\n",
    "pattern_vector=pattern_vector -0.5\n",
    "pattern_vector = pattern_vector.tolist()\n",
    "\n",
    "#finding pairs (combinations) of the pattern vector\n",
    "def find_tuples_index(lst,num=2):\n",
    "     return [i for i in itertools.combinations(enumerate(lst), num)]\n",
    "pair_angle=find_tuples_index(pattern_vector,num=2)\n",
    "#Function to compute angle\n",
    "\n",
    "def find_angle(vector1,vector2): \n",
    "    vector_1=torch.tensor(vector1 , dtype = torch.float)\n",
    "    vector_2=torch.tensor(vector2 , dtype = torch.float)\n",
    "    unit_vector_1 = vector_1 / np.linalg.norm(vector_1)\n",
    "    unit_vector_2 = vector_2 / np.linalg.norm(vector_2)\n",
    "    dot_product = np.dot(unit_vector_1, unit_vector_2)\n",
    "    angle = np.arccos(dot_product)\n",
    "    return math.degrees(angle)\n",
    "\n",
    "angles = []\n",
    "indices = []\n",
    "main =[]\n",
    "for i in range(len(pair_angle)):\n",
    "    #finding angles between the pairs in pair_angle\n",
    "    angles.append(find_angle(pair_angle[i][0][1],pair_angle[i][1][1]))\n",
    "    #indices of the angle \n",
    "    indices.append((pair_angle[i][0][0],pair_angle[i][1][0]))\n",
    "for j in range(len(angles)):\n",
    "    main.append((angles[j] , indices[j]))\n",
    "main=np.array(main)\n",
    "#creating list for appending all similar pairs index\n",
    "similar=[]\n",
    "for k in range(main.shape[0]):\n",
    "    if main[k][0] <= 15:\n",
    "        similar.append((main[k][0] ,main[k][1]))\n",
    "#creating list for appending all cpmplementary pairs index\n",
    "complimentary=[]\n",
    "for l in range(main.shape[0]):\n",
    "    if main[l][0] >= 165:\n",
    "        complimentary.append((main[l][0] ,main[l][1]))\n",
    "print(len(complimentary))\n",
    "print(len(similar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "CT8FhuX56Trz",
    "outputId": "15e86e6c-97b0-47fc-bf2a-773b5da52afc"
   },
   "outputs": [],
   "source": [
    "#cloning the weights for calculation\n",
    "weights_new = model.classifier.weight.data\n",
    "similar_weights = weights_new.clone()\n",
    "out_weights = model.fc.weight.data\n",
    "old_out_weights = out_weights.clone()\n",
    "bias  = model.classifier.bias.data\n",
    "old_bias = bias.clone()\n",
    "print(\"Removing complementary neurons and adding similar weights\\n .......\")\n",
    "# creating a list for the index of neurons that are complementary and needs to be removed\n",
    "to_remove_comp = []\n",
    "for i in complimentary:\n",
    "    if i[1][0] not in to_remove_comp:\n",
    "        to_remove_comp.append(i[1][0])\n",
    "    if i[1][1] not in to_remove_comp:\n",
    "        to_remove_comp.append(i[1][1])\n",
    "#Changing the rows of weight matrix and bais for the corresponding neurons to zero and the column of output weights to zero\n",
    "for i in to_remove_comp:\n",
    "    weights_new[i]=0.0\n",
    "    out_weights[:,i]=0.0\n",
    "    bias[i]=0.0\n",
    "\n",
    "#Adding weights of the similar indices and then removing one of them\n",
    "for i in similar:\n",
    "    weights_new[i[1][1]]+=similar_weights[i[1][0]]\n",
    "    out_weights[:,i[1][1]]+=old_out_weights[:,i[1][0]]\n",
    "    bias[i[1][1]]+=old_bias[i[1][0]]\n",
    "#After adding removing the neurons for which we have added the weight to another \n",
    "for i in similar:\n",
    "    weights_new[i[1][0]] = 0\n",
    "    out_weights[:,i[1][0]]=0\n",
    "    bias[i[1][0]]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LVjtP-Rw6Tr7",
    "outputId": "d7b68092-4496-4c22-db5a-d851b74bb5e7"
   },
   "outputs": [],
   "source": [
    "c=0\n",
    "for i in range(weights_new.shape[0]):\n",
    "    if weights_new[i].cpu().detach().numpy().all()== 0:\n",
    "        c+=1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Vqc1NBcUR3js",
    "outputId": "b19b2584-0786-4b6a-dfb4-d0e43e49f295"
   },
   "outputs": [],
   "source": [
    "model.eval() \n",
    "with torch.no_grad():\n",
    "    correct_r= 0\n",
    "    total_r = 0\n",
    "    pred_r = []\n",
    "    label_r= []\n",
    "    set_seed(0)\n",
    "    for images_r, labels_r in test_loader:\n",
    "        if (torch.cuda.is_available()):\n",
    "\n",
    "          images_r, labels_r = images_r.cuda(), labels_r.cuda()\n",
    "        outputs_r,h_r= model(images_r)\n",
    "        _, predicted_r = torch.max(outputs_r.data, 1)\n",
    "        pred_r.append(predicted_r)\n",
    "        label_r.append(labels_r)\n",
    "        total_r += labels_r.size(0)\n",
    "        correct_r+= (predicted_r == labels_r).sum().item()\n",
    "    l_r = torch.cat(label_r)\n",
    "    pred_r= torch.cat(pred_r)\n",
    "    print('Test Accuracy of the model on the  test images: {:.2f} %'.format(100 * correct_r / total_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "YTt4p0ZM6TsB",
    "outputId": "6022599a-92d7-4987-f5ca-b897835ae527"
   },
   "outputs": [],
   "source": [
    "#class wise precision recall and f1-score\n",
    "print(\"Evaluation of our model on test set after pruning\")\n",
    "testing_pred = pred_r.cpu()\n",
    "actual = l_r.cpu()\n",
    "target_names = ['Angry','Disgust','Fear','Happy','Neutral','Sad','Surprise']\n",
    "print(classification_report(testing_pred,actual,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "F6_Vh8UG6TsK",
    "outputId": "eb5d1c9c-0018-42ed-8621-fa4df9bb3d62"
   },
   "outputs": [],
   "source": [
    "weights_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "SewO_DSQ6TsQ",
    "outputId": "0a7d472a-1469-4370-aa3e-3f3f9fe838cf"
   },
   "outputs": [],
   "source": [
    "model.classifier.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5dRQsT73GPxe",
    "outputId": "ed37f85b-6532-448e-9cb0-b82e104d4d51"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JC-hMXlDu94W"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
